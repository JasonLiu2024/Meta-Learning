{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 14:41:37.766745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib as imp\n",
    "import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([3.])\n",
      "tensor([4.])\n",
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"parallelization example!\"\"\"\n",
    "def div(x : torch.Tensor):\n",
    "    return x + 1\n",
    "a = torch.Tensor([1])\n",
    "b = torch.Tensor([2])\n",
    "c = torch.Tensor([3])\n",
    "d = torch.Tensor([4])\n",
    "\n",
    "f = lambda x : div(x)\n",
    "e, f, g, h = torch.vmap(func=div)(torch.stack([a, b, c, d]))\n",
    "print(e)\n",
    "print(f)\n",
    "print(g)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.]), tensor([3.]), tensor([4.]), tensor([5.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def div_tuple(x : torch.Tensor):\n",
    "    a, b, c, d = x\n",
    "    return (a + 1, b + 1, c + 1, d + 1)\n",
    "torch.vmap(func=div_tuple)((a, b, c, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch of images: torch.Size([7, 32, 32, 3])\n",
      "batch of labels: torch.Size([7, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "number_of_images = 7\n",
    "batch_of_images_list = []\n",
    "for ct in range(number_of_images):\n",
    "    image = torch.randint(0, 255, (32, 32, 3))\n",
    "    batch_of_images_list.append(image)\n",
    "batch_of_images = torch.stack(batch_of_images_list)\n",
    "print(f\"batch of images: {batch_of_images.size()}\")\n",
    "batch_of_labels = torch.stack([torch.randint(0, 24, (1, 1)) for i in range(number_of_images)])\n",
    "print(f\"batch of labels: {batch_of_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 5\n",
    "out_channels = 3\n",
    "weight = torch.zeros(size=[out_channels, 3, kernel_size_0, kernel_size_1])\n",
    "bias = torch.zeros(size=[out_channels])\n",
    "l = layers.CONV(batch_of_images, out_channels, weight, bias)\n",
    "l.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "var, mean = torch.var_mean(a, dim=1)\n",
    "print(a.size())\n",
    "print(var.size())\n",
    "print(mean.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor([2 2 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a_t = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "mean_t, var_t = tf.nn.moments(x=a_t, axes=0)\n",
    "print(a_t)\n",
    "print(var_t)\n",
    "print(mean_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega: torch.Size([3]), corresponding to ways: 3\n",
      "gamma: \n",
      "\tconvolution1_weight: torch.Size([1])\n",
      "\tconvolution1_bias: torch.Size([1])\n",
      "\tconvolution2_weight: torch.Size([1])\n",
      "\tconvolution2_bias: torch.Size([1])\n",
      "\tconvolution3_weight: torch.Size([1])\n",
      "\tconvolution3_bias: torch.Size([1])\n",
      "\tconvolution4_weight: torch.Size([1])\n",
      "\tconvolution4_bias: torch.Size([1])\n",
      "\tdense_weight: torch.Size([1])\n",
      "\tdense_bias: torch.Size([1])\n",
      "zeta: \n",
      "\tconvolution1_weight: torch.Size([32])\n",
      "\tconvolution1_bias: torch.Size([32])\n",
      "\tconvolution2_weight: torch.Size([32])\n",
      "\tconvolution2_bias: torch.Size([32])\n",
      "\tconvolution3_weight: torch.Size([32])\n",
      "\tconvolution3_bias: torch.Size([32])\n",
      "\tconvolution4_weight: torch.Size([32])\n",
      "\tconvolution4_bias: torch.Size([32])\n",
      "KL: 3075.778564453125\n"
     ]
    }
   ],
   "source": [
    "import encoder\n",
    "imp.reload(encoder)\n",
    "ways = 3\n",
    "shots = 5\n",
    "model = encoder.InferenceNetwork(ways=ways, shots=shots, data_name='cifar',\n",
    "                         need_g=True, need_o=True, need_s=True, need_z=True)\n",
    "omega, gamma, zeta, KL = model(batch_of_images.float(), batch_of_labels.float(), True)\n",
    "print(f\"omega: {omega.size()}, corresponding to ways: {ways}\")\n",
    "print(f\"gamma: \")\n",
    "for key in gamma.keys():\n",
    "    print(f\"\\t{key}: {gamma[key].size()}\")\n",
    "print(f\"zeta: \")\n",
    "for key in zeta.keys():\n",
    "    print(f\"\\t{key}: {zeta[key].size()}\")\n",
    "print(f\"KL: {KL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
