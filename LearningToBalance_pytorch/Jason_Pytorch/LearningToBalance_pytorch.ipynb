{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 14:41:37.766745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib as imp\n",
    "import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "op needs to be an Operation. An instance of type list is provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m input_shape \u001b[39m=\u001b[39m (\u001b[39m4\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(input_shape)\n\u001b[1;32m      3\u001b[0m y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\n\u001b[0;32m----> 4\u001b[0m     filters\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mTensor([\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m], \u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m), kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m      5\u001b[0m     activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     dilation_rate\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m      7\u001b[0m     input_shape\u001b[39m=\u001b[39minput_shape[\u001b[39m1\u001b[39m:])(x)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/new/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:417\u001b[0m, in \u001b[0;36mTensor.__init__\u001b[0;34m(self, op, value_index, dtype)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new `Tensor`.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m  TypeError: If the op is not an `Operation`.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(op, Operation):\n\u001b[0;32m--> 417\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mop needs to be an Operation. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn instance of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(op)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is provided.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op \u001b[39m=\u001b[39m op\n\u001b[1;32m    421\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value_index \u001b[39m=\u001b[39m value_index\n",
      "\u001b[0;31mTypeError\u001b[0m: op needs to be an Operation. An instance of type list is provided."
     ]
    }
   ],
   "source": [
    "input_shape = (4, 28, 28, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv2D(\n",
    "    filters=tf.Tensor([2, 2], 1, dtype=float), kernel_size=3,\n",
    "    activation='relu',\n",
    "    dilation_rate=2,\n",
    "    input_shape=input_shape[1:])(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch of images: torch.Size([7, 32, 32, 3])\n",
      "batch of labels: torch.Size([7, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "number_of_images = 7\n",
    "batch_of_images_list = []\n",
    "for ct in range(number_of_images):\n",
    "    image = torch.randint(0, 255, (32, 32, 3))\n",
    "    batch_of_images_list.append(image)\n",
    "batch_of_images = torch.stack(batch_of_images_list)\n",
    "print(f\"batch of images: {batch_of_images.size()}\")\n",
    "batch_of_labels = torch.stack([torch.randint(0, 24, (1, 1)) for i in range(number_of_images)])\n",
    "print(f\"batch of labels: {batch_of_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 5\n",
    "out_channels = 3\n",
    "weight = torch.zeros(size=[out_channels, 3, kernel_size_0, kernel_size_1])\n",
    "bias = torch.zeros(size=[out_channels])\n",
    "l = layers.CONV(batch_of_images, out_channels, weight, bias)\n",
    "l.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "var, mean = torch.var_mean(a, dim=1)\n",
    "print(a.size())\n",
    "print(var.size())\n",
    "print(mean.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor([2 2 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a_t = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "mean_t, var_t = tf.nn.moments(x=a_t, axes=0)\n",
    "print(a_t)\n",
    "print(var_t)\n",
    "print(mean_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega: torch.Size([3]), corresponding to ways: 3\n",
      "gamma: \n",
      "\tconvolution1_weight: torch.Size([1])\n",
      "\tconvolution1_bias: torch.Size([1])\n",
      "\tconvolution2_weight: torch.Size([1])\n",
      "\tconvolution2_bias: torch.Size([1])\n",
      "\tconvolution3_weight: torch.Size([1])\n",
      "\tconvolution3_bias: torch.Size([1])\n",
      "\tconvolution4_weight: torch.Size([1])\n",
      "\tconvolution4_bias: torch.Size([1])\n",
      "\tdense_weight: torch.Size([1])\n",
      "\tdense_bias: torch.Size([1])\n",
      "zeta: \n",
      "\tconvolution1_weight: torch.Size([32])\n",
      "\tconvolution1_bias: torch.Size([32])\n",
      "\tconvolution2_weight: torch.Size([32])\n",
      "\tconvolution2_bias: torch.Size([32])\n",
      "\tconvolution3_weight: torch.Size([32])\n",
      "\tconvolution3_bias: torch.Size([32])\n",
      "\tconvolution4_weight: torch.Size([32])\n",
      "\tconvolution4_bias: torch.Size([32])\n",
      "KL: 3075.778564453125\n"
     ]
    }
   ],
   "source": [
    "import encoder\n",
    "imp.reload(encoder)\n",
    "ways = 3\n",
    "shots = 5\n",
    "model = encoder.InferenceNetwork(ways=ways, shots=shots, data_name='cifar',\n",
    "                         need_g=True, need_o=True, need_s=True, need_z=True)\n",
    "omega, gamma, zeta, KL = model(batch_of_images.float(), batch_of_labels.float(), True)\n",
    "print(f\"omega: {omega.size()}, corresponding to ways: {ways}\")\n",
    "print(f\"gamma: \")\n",
    "for key in gamma.keys():\n",
    "    print(f\"\\t{key}: {gamma[key].size()}\")\n",
    "print(f\"zeta: \")\n",
    "for key in zeta.keys():\n",
    "    print(f\"\\t{key}: {zeta[key].size()}\")\n",
    "print(f\"KL: {KL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
