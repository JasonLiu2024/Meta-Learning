{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib as imp\n",
    "# specific classes for training, validating, and testing, \n",
    "# as described in LearningToBalance original code\n",
    "train_class_names = [\n",
    "    'train', 'skyscraper', 'turtle', 'raccoon', 'spider', 'orange', 'castle', 'keyboard',\n",
    "    'clock', 'pear', 'girl', 'seal', 'elephant', 'apple', 'aquarium_fish', 'bus',\n",
    "    'mushroom', 'possum', 'squirrel', 'chair', 'tank', 'plate', 'wolf', 'road', 'mouse',\n",
    "    'boy', 'shrew', 'couch', 'sunflower', 'tiger', 'caterpillar', 'lion', 'streetcar',\n",
    "    'lawn_mower', 'tulip', 'forest', 'dolphin', 'cockroach', 'bear', 'porcupine', 'bee',\n",
    "    'hamster', 'lobster', 'bowl', 'can', 'bottle', 'trout', 'snake', 'bridge',\n",
    "    'pine_tree', 'skunk', 'lizard', 'cup', 'kangaroo', 'oak_tree', 'dinosaur', 'rabbit',\n",
    "    'orchid', 'willow_tree', 'ray', 'palm_tree', 'mountain', 'house', 'cloud'\n",
    "    ]\n",
    "valid_class_names = [\n",
    "    'otter', 'motorcycle', 'television', 'lamp', 'crocodile', 'shark', 'butterfly', 'sea',\n",
    "    'beaver', 'beetle', 'tractor', 'flatfish', 'maple_tree', 'camel', 'crab', 'cattle'\n",
    "    ]\n",
    "test_class_names = [\n",
    "    'baby', 'bed', 'bicycle', 'chimpanzee', 'fox', 'leopard', 'man', 'pickup_truck',\n",
    "    'plain', 'poppy', 'rocket', 'rose', 'snail', 'sweet_pepper', 'table', 'telephone',\n",
    "    'wardrobe', 'whale', 'woman', 'worm'\n",
    "    ]\n",
    "# \n",
    "LABEL_NAMES : list[str] = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK batch\n",
      "type:   <class 'list'>\n",
      "length: 4\n",
      "\ttask 0\n",
      "\tshape of img_supp: torch.Size([21, 32, 32, 3])\n",
      "\tshape of lbl_supp: torch.Size([21])\n",
      "\tshape of img_quer: torch.Size([6, 32, 32, 3])\n",
      "\tshape of lbl_quer: torch.Size([6])\n",
      "\ttask 1\n",
      "\tshape of img_supp: torch.Size([21, 32, 32, 3])\n",
      "\tshape of lbl_supp: torch.Size([21])\n",
      "\tshape of img_quer: torch.Size([6, 32, 32, 3])\n",
      "\tshape of lbl_quer: torch.Size([6])\n",
      "\ttask 2\n",
      "\tshape of img_supp: torch.Size([21, 32, 32, 3])\n",
      "\tshape of lbl_supp: torch.Size([21])\n",
      "\tshape of img_quer: torch.Size([6, 32, 32, 3])\n",
      "\tshape of lbl_quer: torch.Size([6])\n",
      "\ttask 3\n",
      "\tshape of img_supp: torch.Size([21, 32, 32, 3])\n",
      "\tshape of lbl_supp: torch.Size([21])\n",
      "\tshape of img_quer: torch.Size([6, 32, 32, 3])\n",
      "\tshape of lbl_quer: torch.Size([6])\n",
      "\ttask 4\n",
      "\tshape of img_supp: torch.Size([21, 32, 32, 3])\n",
      "\tshape of lbl_supp: torch.Size([21])\n",
      "\tshape of img_quer: torch.Size([6, 32, 32, 3])\n",
      "\tshape of lbl_quer: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# verify that Data/get_dataloader works!\n",
    "from Data import get_dataloader\n",
    "\n",
    "max_number_of_shot = 7\n",
    "number_of_query = 2\n",
    "way = 3\n",
    "total_task = 9\n",
    "batch_size = 5\n",
    "some_dataloader = get_dataloader(valid_class_names, max_number_of_shot, number_of_query, way, total_tasks=total_task, batch_size=batch_size)\n",
    "# test_index = 9\n",
    "# test_image = d[LABEL_NAMES.index((valid_class_names[0]))]['image'][test_index]\n",
    "# test_label = LABEL_NAMES[d[LABEL_NAMES.index((valid_class_names[0]))]['label'][test_index]]\n",
    "# f, ax = plt.subplots(figsize=(2, 2))\n",
    "# ax.imshow(test_image)\n",
    "# ax.set_title(test_label)\n",
    "# c = 0\n",
    "# for i, task_batch in enumerate(some_dataloader):\n",
    "#     print(f\"TASK batch\")\n",
    "#     print(f\"type:   {type(task_batch)}\")\n",
    "#     print(f\"length: {len(task_batch)}\")\n",
    "#     for c in range(batch_size):\n",
    "#         print(f\"\\ttask {c}\")\n",
    "#         # print(task[0].shape)\n",
    "#         # print(task[1].shape)\n",
    "#         # print(task[2].shape)\n",
    "#         # print(task[3].shape)\n",
    "#         # print(task[4].shape)\n",
    "#         img_supp = task_batch[0][c]\n",
    "#         lbl_supp = task_batch[1][c]\n",
    "#         img_quer = task_batch[2][c]\n",
    "#         lbl_quer = task_batch[3][c]\n",
    "#         # print(lbl_quer)\n",
    "#         print(f\"\\tshape of img_supp: {img_supp.shape}\")\n",
    "#         print(f\"\\tshape of lbl_supp: {lbl_supp.shape}\")\n",
    "#         print(f\"\\tshape of img_quer: {img_quer.shape}\")\n",
    "#         print(f\"\\tshape of lbl_quer: {lbl_quer.shape}\")\n",
    "#     if c == 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model, get_parameter, generating params theta\n",
      "model, get_parameter, generating params alpha\n",
      "T-R-A-I-N\n",
      "train_dataloader length? 16\n",
      "valid_dataloader length? 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/new/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 47.54 GiB total capacity; 23.83 GiB already allocated; 6.75 MiB free; 25.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     16\u001b[0m m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mLearningToBalance(data_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, number_of_inner_gradient_steps\u001b[39m=\u001b[39mnumber_of_inner_gradient_steps, \n\u001b[1;32m     17\u001b[0m         ways\u001b[39m=\u001b[39mways, shots\u001b[39m=\u001b[39mshots, inner_learning_rate\u001b[39m=\u001b[39minner_learning_rate, outer_learning_rate\u001b[39m=\u001b[39mouter_learning_rate, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m---> 18\u001b[0m train_loss, valid_loss, train_accuracy, valid_accuracy \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     19\u001b[0m         train_dataloader\u001b[39m=\u001b[39;49mData\u001b[39m.\u001b[39;49mget_dataloader(train_class_names, shots, query, ways, total_train_task, batch_size),\n\u001b[1;32m     20\u001b[0m         valid_dataloader\u001b[39m=\u001b[39;49mData\u001b[39m.\u001b[39;49mget_dataloader(valid_class_names, shots, query, ways, total_valid_task, batch_size))\n\u001b[1;32m     21\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mtest(test_dataloader\u001b[39m=\u001b[39m\n\u001b[1;32m     22\u001b[0m        Data\u001b[39m.\u001b[39mget_dataloader(test_class_names, shots, query, ways, total_test_task, batch_size))\n\u001b[1;32m     23\u001b[0m f, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m), nrows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, ncols\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/ml/LearningToBalance_pytorch/Jason_Pytorch/model.py:314\u001b[0m, in \u001b[0;36mLearningToBalance.train\u001b[0;34m(self, train_dataloader, valid_dataloader)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39m# print(f\"train step {step}\")\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m# enumerated dataloader is a list[tuple[stuffs]]\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# print(f\"type of dataloader: {type(train_dataloader)}\")\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# print(f\"type of task batch: {type(task_batch)}\")\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 314\u001b[0m outer_loss, outer_accuracy, KL, inner_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outer_step_(task_batch, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    315\u001b[0m \u001b[39m# print(f\"ran _outer_step()\")\u001b[39;00m\n\u001b[1;32m    316\u001b[0m outer_loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/ml/LearningToBalance_pytorch/Jason_Pytorch/model.py:278\u001b[0m, in \u001b[0;36mLearningToBalance._outer_step_\u001b[0;34m(self, input_task_batch, train)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size):\n\u001b[1;32m    274\u001b[0m \u001b[39m# \"\"\"possible improvement: use torch.vmap instead of calculating one by one\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m   \u001b[39m# print(f\"length of input_task_batch: {input_task[0].shape}\")\u001b[39;00m\n\u001b[1;32m    276\u001b[0m   input_task \u001b[39m=\u001b[39m (input_task_batch[\u001b[39m0\u001b[39m][t], input_task_batch[\u001b[39m1\u001b[39m][t], \n\u001b[1;32m    277\u001b[0m                 input_task_batch[\u001b[39m2\u001b[39m][t], input_task_batch[\u001b[39m3\u001b[39m][t])\n\u001b[0;32m--> 278\u001b[0m   cross_entropy, outer_accuracy, KL, prediction, inner_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outer_step_single_task(input_task, train)\n\u001b[1;32m    279\u001b[0m   \u001b[39m# print(f\"cross_entropy {cross_entropy}\")\u001b[39;00m\n\u001b[1;32m    280\u001b[0m   cross_entropy_list\u001b[39m.\u001b[39mappend(cross_entropy)\n",
      "File \u001b[0;32m~/ml/LearningToBalance_pytorch/Jason_Pytorch/model.py:254\u001b[0m, in \u001b[0;36mLearningToBalance._outer_step_single_task\u001b[0;34m(self, input_task, train)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameter\u001b[39m.\u001b[39mupdate(theta_update_by_zeta)\n\u001b[1;32m    253\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"inner gradient steps; omega & gamma for task_specific modulation\"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m theta_update_by_inner_loop, inner_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inner_loop(x_train, y_train, train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameter, omega, gamma)\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameter\u001b[39m.\u001b[39mupdate(theta_update_by_inner_loop)\n\u001b[1;32m    256\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"outer-loss & test_accuracy\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/ml/LearningToBalance_pytorch/Jason_Pytorch/model.py:194\u001b[0m, in \u001b[0;36mLearningToBalance._inner_loop\u001b[0;34m(self, x_train, y_train, train, theta, omega, gamma)\u001b[0m\n\u001b[1;32m    192\u001b[0m y_train \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint64)\n\u001b[1;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_of_inner_gradient_steps):\n\u001b[0;32m--> 194\u001b[0m   inner_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_theta(x_train, theta)\n\u001b[1;32m    195\u001b[0m   \u001b[39m# print(f\"\\tinner_logits shape: {inner_logits.shape}, dtype: {inner_logits.dtype}\")\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[39m# print(f\"\\ty_train shape:      {y_train.shape}, dtype: {y_train.dtype}\")\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   cross_entropy_per_class \u001b[39m=\u001b[39m CrossEntropy_Class(inner_logits, y_train)\n",
      "File \u001b[0;32m~/ml/LearningToBalance_pytorch/Jason_Pytorch/model.py:130\u001b[0m, in \u001b[0;36mLearningToBalance.forward_theta\u001b[0;34m(self, x, theta)\u001b[0m\n\u001b[1;32m    125\u001b[0m   bias \u001b[39m=\u001b[39m theta[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconvolution_\u001b[39m\u001b[39m{\u001b[39;00ml\u001b[39m}\u001b[39;00m\u001b[39m_bias\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    126\u001b[0m   \u001b[39m# more steps inside ConvolutionBlock_F, compared to original MAML code!\u001b[39;00m\n\u001b[1;32m    127\u001b[0m   \u001b[39m# print(f\"\\tconv layer {l}, weight shape {theta[f'convolution_{l}_weight'].shape}\")\u001b[39;00m\n\u001b[1;32m    128\u001b[0m   \u001b[39m# print(f\"\\tconv layer {l}, bias shape   {theta[f'convolution_{l}_bias'].shape}\")\u001b[39;00m\n\u001b[1;32m    129\u001b[0m   \u001b[39m# print(f\"\\tinput dimension: {x.shape}\")\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m   x \u001b[39m=\u001b[39m ConvolutionBlock_F(x, weight, bias) \u001b[39m# just executes the calculation\u001b[39;00m\n\u001b[1;32m    131\u001b[0m weight \u001b[39m=\u001b[39m theta[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdense_weight\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m bias \u001b[39m=\u001b[39m theta[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdense_bias\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/ml/LearningToBalance_pytorch/Jason_Pytorch/layers.py:64\u001b[0m, in \u001b[0;36mConvolutionBlock_F\u001b[0;34m(x, weight, bias)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mConvolutionBlock_F\u001b[39m(x : torch\u001b[39m.\u001b[39mTensor, \n\u001b[1;32m     63\u001b[0m   weight : torch\u001b[39m.\u001b[39mTensor, bias : torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 64\u001b[0m   x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mconv2d(x, weight, bias, stride\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     65\u001b[0m   x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     66\u001b[0m   x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbatch_norm(x, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 47.54 GiB total capacity; 23.83 GiB already allocated; 6.75 MiB free; 25.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import Data\n",
    "imp.reload(Data)\n",
    "imp.reload(model)\n",
    "# data_name : str = 'cifar'\n",
    "number_of_inner_gradient_steps: int = 1\n",
    "ways: int = 7\n",
    "shots: int = 10\n",
    "query: int = 3\n",
    "total_train_task = 80\n",
    "total_valid_task = 10\n",
    "total_test_task = 20\n",
    "inner_learning_rate: float = 1e-4\n",
    "outer_learning_rate: float = 1e-4\n",
    "batch_size = 5\n",
    "m = model.LearningToBalance(data_name='cifar', number_of_inner_gradient_steps=number_of_inner_gradient_steps, \n",
    "        ways=ways, shots=shots, inner_learning_rate=inner_learning_rate, outer_learning_rate=outer_learning_rate, batch_size=batch_size)\n",
    "train_loss, valid_loss, train_accuracy, valid_accuracy = m.train(\n",
    "        train_dataloader=Data.get_dataloader(train_class_names, shots, query, ways, total_train_task, batch_size),\n",
    "        valid_dataloader=Data.get_dataloader(valid_class_names, shots, query, ways, total_valid_task, batch_size))\n",
    "test_loss, test_accuracy = m.test(test_dataloader=\n",
    "       Data.get_dataloader(test_class_names, shots, query, ways, total_test_task, batch_size))\n",
    "f, ax = plt.subplots(figsize=(4, 4), nrows=1, ncols=3)\n",
    "ax[0].plot(train_loss)\n",
    "ax[1].plot(valid_loss)\n",
    "ax[2].plot(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([3.])\n",
      "tensor([4.])\n",
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"parallelization example, using vmap!\"\"\"\n",
    "# def div(x : torch.Tensor):\n",
    "#     return x + 1\n",
    "# a = torch.Tensor([1])\n",
    "# b = torch.Tensor([2])\n",
    "# c = torch.Tensor([3])\n",
    "# d = torch.Tensor([4])\n",
    "\n",
    "# f = lambda x : div(x)\n",
    "# e, f, g, h = torch.vmap(func=div)(torch.stack([a, b, c, d]))\n",
    "# print(e)\n",
    "# print(f)\n",
    "# print(g)\n",
    "# print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega: torch.Size([3]), corresponding to ways: 3\n",
      "gamma: \n",
      "\tconvolution1_weight: torch.Size([1])\n",
      "\tconvolution1_bias: torch.Size([1])\n",
      "\tconvolution2_weight: torch.Size([1])\n",
      "\tconvolution2_bias: torch.Size([1])\n",
      "\tconvolution3_weight: torch.Size([1])\n",
      "\tconvolution3_bias: torch.Size([1])\n",
      "\tconvolution4_weight: torch.Size([1])\n",
      "\tconvolution4_bias: torch.Size([1])\n",
      "\tdense_weight: torch.Size([1])\n",
      "\tdense_bias: torch.Size([1])\n",
      "zeta: \n",
      "\tconvolution1_weight: torch.Size([32])\n",
      "\tconvolution1_bias: torch.Size([32])\n",
      "\tconvolution2_weight: torch.Size([32])\n",
      "\tconvolution2_bias: torch.Size([32])\n",
      "\tconvolution3_weight: torch.Size([32])\n",
      "\tconvolution3_bias: torch.Size([32])\n",
      "\tconvolution4_weight: torch.Size([32])\n",
      "\tconvolution4_bias: torch.Size([32])\n",
      "KL: 3075.778564453125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"simple test of inference network\"\"\"\n",
    "# import encoder\n",
    "# imp.reload(encoder)\n",
    "# ways = 3\n",
    "# shots = 5\n",
    "# model = encoder.InferenceNetwork(ways=ways, shots=shots, data_name='cifar',\n",
    "#                          need_g=True, need_o=True, need_s=True, need_z=True)\n",
    "# omega, gamma, zeta, KL = model(batch_of_images.float(), batch_of_labels.float(), True)\n",
    "# print(f\"omega: {omega.size()}, corresponding to ways: {ways}\")\n",
    "# print(f\"gamma: \")\n",
    "# for key in gamma.keys():\n",
    "#     print(f\"\\t{key}: {gamma[key].size()}\")\n",
    "# print(f\"zeta: \")\n",
    "# for key in zeta.keys():\n",
    "#     print(f\"\\t{key}: {zeta[key].size()}\")\n",
    "# print(f\"KL: {KL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
