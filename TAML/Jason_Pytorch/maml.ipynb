{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Model-Agnostic Meta Learning algorithm (MAML) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 18:37:38.744106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"setup information\"\"\"\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import maml\n",
    "import Data\n",
    "import importlib as imp\n",
    "import numpy as np\n",
    "import encoder\n",
    "\"\"\"dataset split as specified by the authors\"\"\"\n",
    "train_class_names = [\n",
    "    'train', 'skyscraper', 'turtle', 'raccoon', 'spider', 'orange', 'castle', 'keyboard',\n",
    "    'clock', 'pear', 'girl', 'seal', 'elephant', 'apple', 'aquarium_fish', 'bus',\n",
    "    'mushroom', 'possum', 'squirrel', 'chair', 'tank', 'plate', 'wolf', 'road', 'mouse',\n",
    "    'boy', 'shrew', 'couch', 'sunflower', 'tiger', 'caterpillar', 'lion', 'streetcar',\n",
    "    'lawn_mower', 'tulip', 'forest', 'dolphin', 'cockroach', 'bear', 'porcupine', 'bee',\n",
    "    'hamster', 'lobster', 'bowl', 'can', 'bottle', 'trout', 'snake', 'bridge',\n",
    "    'pine_tree', 'skunk', 'lizard', 'cup', 'kangaroo', 'oak_tree', 'dinosaur', 'rabbit',\n",
    "    'orchid', 'willow_tree', 'ray', 'palm_tree', 'mountain', 'house', 'cloud'\n",
    "    ]\n",
    "valid_class_names = [\n",
    "    'otter', 'motorcycle', 'television', 'lamp', 'crocodile', 'shark', 'butterfly', 'sea',\n",
    "    'beaver', 'beetle', 'tractor', 'flatfish', 'maple_tree', 'camel', 'crab', 'cattle'\n",
    "    ]\n",
    "test_class_names = [\n",
    "    'baby', 'bed', 'bicycle', 'chimpanzee', 'fox', 'leopard', 'man', 'pickup_truck',\n",
    "    'plain', 'poppy', 'rocket', 'rose', 'snail', 'sweet_pepper', 'table', 'telephone',\n",
    "    'wardrobe', 'whale', 'woman', 'worm'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 47.54 GiB total capacity; 9.65 GiB already allocated; 8.75 MiB free; 9.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m total_test_task \u001b[39m=\u001b[39m \u001b[39m600\u001b[39m \u001b[39m# 600\u001b[39;00m\n\u001b[1;32m     17\u001b[0m imbalance \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m m \u001b[39m=\u001b[39m maml\u001b[39m.\u001b[39;49mMAML(num_outputs\u001b[39m=\u001b[39;49mways, \n\u001b[1;32m     19\u001b[0m             num_inner_steps\u001b[39m=\u001b[39;49mnumber_of_inner_gradient_steps,\n\u001b[1;32m     20\u001b[0m             inner_lr\u001b[39m=\u001b[39;49minner_learning_rate, learn_inner_lrs\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m     21\u001b[0m             outer_lr\u001b[39m=\u001b[39;49mouter_learning_rate)\n\u001b[1;32m     22\u001b[0m \u001b[39m# m._view_model(m._meta_parameters)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss_list, accuracy_list \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mtrain(\n\u001b[1;32m     24\u001b[0m     dataloader_train\u001b[39m=\u001b[39mData\u001b[39m.\u001b[39mget_dataloader(train_class_names, max_shots, query, ways, total_train_task, batch_size, imbalance),\n\u001b[1;32m     25\u001b[0m     dataloader_val\u001b[39m=\u001b[39mData\u001b[39m.\u001b[39mget_dataloader(valid_class_names, max_shots, query, ways, total_valid_task, batch_size, imbalance),\n\u001b[1;32m     26\u001b[0m     writer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/ml/TAML/Jason_Pytorch/maml.py:63\u001b[0m, in \u001b[0;36mMAML.__init__\u001b[0;34m(self, num_outputs, num_inner_steps, inner_lr, learn_inner_lrs, outer_lr)\u001b[0m\n\u001b[1;32m     60\u001b[0m in_channels \u001b[39m=\u001b[39m NUM_INPUT_CHANNELS\n\u001b[1;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_CONV_LAYERS):\n\u001b[1;32m     62\u001b[0m     meta_parameters[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mxavier_uniform_(\n\u001b[0;32m---> 63\u001b[0m         torch\u001b[39m.\u001b[39;49mempty(\n\u001b[1;32m     64\u001b[0m             NUM_HIDDEN_CHANNELS,\n\u001b[1;32m     65\u001b[0m             in_channels,\n\u001b[1;32m     66\u001b[0m             KERNEL_SIZE,\n\u001b[1;32m     67\u001b[0m             KERNEL_SIZE,\n\u001b[1;32m     68\u001b[0m             requires_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     69\u001b[0m             device\u001b[39m=\u001b[39;49mDEVICE\n\u001b[1;32m     70\u001b[0m         )\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m     meta_parameters[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mzeros_(\n\u001b[1;32m     73\u001b[0m         torch\u001b[39m.\u001b[39mempty(\n\u001b[1;32m     74\u001b[0m             NUM_HIDDEN_CHANNELS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     )\n\u001b[1;32m     79\u001b[0m     in_channels \u001b[39m=\u001b[39m NUM_HIDDEN_CHANNELS\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 47.54 GiB total capacity; 9.65 GiB already allocated; 8.75 MiB free; 9.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# to run: jupyter nbconvert --execute --to notebook TAML_notebook.ipynb\n",
    "imp.reload(maml)\n",
    "imp.reload(encoder)\n",
    "imp.reload(Data)\n",
    "number_of_inner_gradient_steps: int = 5\n",
    "ways: int = 5 # 5\n",
    "max_shots: int = 50 # 50\n",
    "query: int = 15 # 15\n",
    "iterations = 7 # epochsï¼Œ 1000\n",
    "inner_learning_rate: float = 0.5\n",
    "outer_learning_rate: float = 1e-3\n",
    "batch_size = 4 # how many tasks in this batch\n",
    "total_train_task = batch_size * iterations\n",
    "valid_interval = 7 # was 50\n",
    "total_valid_task = batch_size * int(iterations / valid_interval)\n",
    "total_test_task = 600 # 600\n",
    "imbalance = False\n",
    "m = maml.MAML(num_outputs=ways, \n",
    "            num_inner_steps=number_of_inner_gradient_steps,\n",
    "            inner_lr=inner_learning_rate, learn_inner_lrs=False, \n",
    "            outer_lr=outer_learning_rate)\n",
    "# m._view_model(m._meta_parameters)\n",
    "loss_list, accuracy_list = m.train(\n",
    "    dataloader_train=Data.get_dataloader(train_class_names, max_shots, query, ways, total_train_task, batch_size, imbalance),\n",
    "    dataloader_val=Data.get_dataloader(valid_class_names, max_shots, query, ways, total_valid_task, batch_size, imbalance),\n",
    "    writer=None)\n",
    "# test_loss, test_accuracy = m.test( \n",
    "#     dataloader_test =Data.get_dataloader(test_class_names,  max_shots, query, ways, total_valid_task, batch_size, imbalance))\n",
    "# plot results:\n",
    "f, ax = plt.subplots(figsize=(32, 16), nrows=2, ncols=2)\n",
    "# plot train\n",
    "ax[0, 0].plot(loss_list)\n",
    "ax[0, 0].set_title(\"train loss\")\n",
    "ax[1, 0].plot(accuracy_list)\n",
    "ax[1, 0].set_title(\"train accuracy\")\n",
    "# plot valid\n",
    "# ax[0, 1].plot(valid_loss)\n",
    "# ax[0, 1].set_title(\"valid loss\")\n",
    "# ax[1, 1].plot(valid_accuracy)\n",
    "# ax[1, 1].set_title(\"valid accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
