{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "# tf.enable_eager_execution() # makes code super slow!\n",
    "# # Meta-training\n",
    "# $ python main.py \\\n",
    "#   --gpu_id 0 \\\n",
    "#   --savedir \"./results/cifar/taml\" --id_dataset 'cifar' --ood_dataset 'svhn' \\\n",
    "#   --mode 'meta_train' --metabatch 4 --n_steps 5 --way 5 --max_shot 50 --query 15 \\\n",
    "#   --n_train_iters 50000 --meta_lr 1e-3 \\\n",
    "#   --alpha_on --omega_on --gamma_on --z_on\n",
    "# Meta-testing\n",
    "# $ python main.py \\\n",
    "#   --gpu_id 0 \\\n",
    "#   --savedir \"./results/cifar/taml\" --id_dataset 'cifar' --ood_dataset 'svhn' \\\n",
    "#   --mode 'meta_test' --metabatch 4 --n_steps 10 --way 5 --max_shot 50 --query 15 \\\n",
    "#   --n_test_episodes 1000 \\\n",
    "#   --alpha_on --omega_on --gamma_on --z_on --n_mc_samples 10\n",
    "class Arg():\n",
    "    def __init__(self):\n",
    "        self.gpu_id = 0\n",
    "        self.savedir = \"./results/cifar/taml\"\n",
    "        self.id_dataset = ['cifar']\n",
    "        self.ood_dataset = ['svhn']\n",
    "        self.mode = 'meta_train'\n",
    "        self.metabatch = 4\n",
    "        self.n_steps = 5\n",
    "        self.way = 5\n",
    "        self.max_shot = 3\n",
    "        self.query = 2\n",
    "        self.n_train_iters = 1 # actual: 50000\n",
    "        self.n_train_iters = 1\n",
    "        self.meta_lr = 1e-3\n",
    "        self.alpha_on = True\n",
    "        self.omega_on = True\n",
    "        self.gamma_on = True\n",
    "        self.z_on = True\n",
    "        self.n_mc_samples = 10\n",
    "        self.inner_lr = 0.5\n",
    "args = Arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'imp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e650547bebbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mencoder_tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInferenceNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imp' is not defined"
     ]
    }
   ],
   "source": [
    "import encoder_tf\n",
    "imp.reload(encoder_tf)\n",
    "encoder = encoder_tf.InferenceNetwork(args)\n",
    "x_train = tf.constant(np.ones(shape=(10, 32, 32, 3)).astype('float64'))\n",
    "y_train = tf.constant(np.ones(shape=(10, 1)))\n",
    "x_test  = tf.constant(np.ones(shape=(15, 32, 32, 3)))\n",
    "y_test  = tf.constant(np.ones(shape=(15, 1)))\n",
    "encoder.forward(inputs=(x_train, y_train), sample=True, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  [18 19 13 54 41]\n",
      "y_tr dimension for current class:  (3, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (3, 5)\n",
      "classes:  [61 50 25  4 27]\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "classes:  [31  5 33 36 58]\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "y_tr dimension for current class:  (2, 5)\n",
      "(3, 12, 3072)\n",
      "(3, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "import data_tf\n",
    "imp.reload(data_tf)\n",
    "from collections import OrderedDict\n",
    "# id_data =   OrderedDict([(data, data_tf.Data(data)) for data in args.id_dataset])\n",
    "d = data_tf.Data(args.id_dataset[0])\n",
    "xtr_all, ytr_all, xte_all, yte_all = d.generate_episode(args, split='mtr', n_episodes=3, mode=1)\n",
    "print(xtr_all.shape)\n",
    "print(ytr_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||encoder: get_posterior()\n",
      "x shape:  (12, 3072)\n",
      "y shape:  (12, 5)\n",
      "<<<<encoder 1>>>\n",
      "x reshaped before convolution:  (12, 32, 32, 3)\n",
      "x after convolution 1:  (12, 32, 32, 10)\n",
      "x after max pooling 1:  (12, 16, 16, 10)\n",
      "x after convolution 2:  (12, 16, 16, 10)\n",
      "x after max pooling 2:  (12, 8, 8, 10)\n",
      "x after flatten:  (12, 640)\n",
      "x after dense layer:  (12, 64)\n",
      "<<<statistics pooling 1>>>\n",
      "y_sum: (sum reduced along dimension 1) Tensor(\"Sum_18:0\", shape=(12,), dtype=float64)\n",
      "y_ (argmax of y on dimension 1) :  Tensor(\"ArgMax_2:0\", shape=(12,), dtype=int64)\n",
      "iterate over number of classes 5\n",
      "\tN_c:  ()\n",
      "\tx_c shape:  (?, 64)\n",
      "|||encoder: _statistics_pooling\n",
      "\ts_c (from statistics pooling x_c:  Tensor(\"stack_14:0\", shape=(64, 3), dtype=float64)\n",
      "\tN_c:  ()\n",
      "\tx_c shape:  (?, 64)\n",
      "|||encoder: _statistics_pooling\n",
      "\ts_c (from statistics pooling x_c:  Tensor(\"stack_15:0\", shape=(64, 3), dtype=float64)\n",
      "\tN_c:  ()\n",
      "\tx_c shape:  (?, 64)\n",
      "|||encoder: _statistics_pooling\n",
      "\ts_c (from statistics pooling x_c:  Tensor(\"stack_16:0\", shape=(64, 3), dtype=float64)\n",
      "\tN_c:  ()\n",
      "\tx_c shape:  (?, 64)\n",
      "|||encoder: _statistics_pooling\n",
      "\ts_c (from statistics pooling x_c:  Tensor(\"stack_17:0\", shape=(64, 3), dtype=float64)\n",
      "\tN_c:  ()\n",
      "\tx_c shape:  (?, 64)\n",
      "|||encoder: _statistics_pooling\n",
      "\ts_c (from statistics pooling x_c:  Tensor(\"stack_18:0\", shape=(64, 3), dtype=float64)\n",
      "final s (stacked from the 's_c's):  (5, 64, 3)\n",
      "s after dense layer:  (5, 64, 4)\n",
      "s reshape:  (5, 256)\n",
      "<<<encoder 2>>>\n",
      "v, result of s after dense layer,  (5, 128)\n",
      "v, another dense layer,  (5, 32)\n",
      "<<<statistics pooling 2>>>\n",
      "|||encoder: _statistics_pooling\n",
      "v after statistics pooling:  (32, 3)\n",
      "v after expanded dims,  (1, 32, 3)\n",
      "v after dense layer:  (1, 32, 4)\n",
      "v reshaped:  (1, 128)\n",
      "<<<omega>>>\n",
      "using omega?  False\n",
      "\ts1, result of s after dense layer:  (5, 64)\n",
      "mu omega: from dense layer (5, 1)\n",
      "sigma omega: from dense layer (5, 1)\n",
      "mu omega, squeezed:  (5,)\n",
      "sigma omega, squeezed:  (5,)\n",
      "-> acquired omega posterior distribution\n",
      "<<<gamma>>>\n",
      "\tv1, result of v after dense layer:  (1, 64)\n",
      "mu gamma: from dense layer (1, 5)\n",
      "sigma gamma: from dense layer (1, 5)\n",
      "mu gamma, squeezed:  (5,)\n",
      "sigma gamma, squeezed:  (5,)\n",
      "-> acquired gamma posterior distribution\n",
      "<<<zeta>>>\n",
      "\tv2, result of v after dense layer:  (1, 64)\n",
      "mu zeta: from dense layer (1, 256)\n",
      "sigma zeta: from dense layer (1, 256)\n",
      "mu zeta, squeezed:  (256,)\n",
      "sigma zeta, squeezed:  (256,)\n",
      "-> acquired zeta posterior distribution\n",
      "kl omega shape:  ()\n",
      "kl gamma shape:  ()\n",
      "kl zeta shape:  ()\n",
      "omega shape:  (5,)\n",
      "g_ shape:  (5,)\n",
      "g_ shape:  (1,) g_ length 5\n",
      "z_ shape:  (256,)\n",
      "how many zw_s:  4 range:  128 num or size:  32\n",
      "zw_ element shape:  (32,) (32,) (32,)\n",
      "how many zb_s:  4\n",
      "zb_ element shape:  (32,)\n"
     ]
    }
   ],
   "source": [
    "import encoder_tf\n",
    "imp.reload(encoder_tf)\n",
    "encoder = encoder_tf.InferenceNetwork(args)\n",
    "omega, gamma, zeta, KL = encoder.forward(inputs=(xtr_all[0], ytr_all[0]), sample=True, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omega, shape {omega.shape}\n",
      "Gamma, a dictionary:\n",
      "\t {'conv2_b'} shape: (1,)\n",
      "\t {'conv1_b'} shape: (1,)\n",
      "\t {'conv1_w'} shape: (1,)\n",
      "\t {'conv3_b'} shape: (1,)\n",
      "\t {'conv2_w'} shape: (1,)\n",
      "\t {'conv4_w'} shape: (1,)\n",
      "\t {'conv3_w'} shape: (1,)\n",
      "\t {'conv4_b'} shape: (1,)\n",
      "\t {'dense_b'} shape: (1,)\n",
      "\t {'dense_w'} shape: (1,)\n",
      "Zeta, a dictionary:\n",
      "\t {'conv2_b'} shape: (32,)\n",
      "\t {'conv1_b'} shape: (32,)\n",
      "\t {'conv1_w'} shape: (32,)\n",
      "\t {'conv3_b'} shape: (32,)\n",
      "\t {'conv2_w'} shape: (32,)\n",
      "\t {'conv4_w'} shape: (32,)\n",
      "\t {'conv3_w'} shape: (32,)\n",
      "\t {'conv4_b'} shape: (32,)\n",
      "KL:  Tensor(\"add_7:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Omega, shape {omega.shape}\")\n",
    "print(\"Gamma, a dictionary:\")\n",
    "for parameter_name in gamma.keys():\n",
    "    print(\"\\t\", {parameter_name}, \"shape:\", gamma[parameter_name].shape)\n",
    "print(\"Zeta, a dictionary:\")\n",
    "for parameter_name in zeta.keys():\n",
    "    print(\"\\t\", {parameter_name}, \"shape:\", zeta[parameter_name].shape)\n",
    "print(\"KL: \", KL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtr: <class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n",
      "xtr: <class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2322\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2323\u001b[1;33m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2324\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'map/while/MaxPool_23' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2326\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'map/while/MaxPool_23' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2b11e2302d03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'meta_train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0mmeta_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'meta_test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[0mmeta_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2b11e2302d03>\u001b[0m in \u001b[0;36mmeta_train\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[0mouter_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_cent\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnet_kl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m   meta_train_op = get_train_op(optim, outer_loss, clip=[-3., 3.],\n\u001b[1;32m---> 49\u001b[1;33m       global_step=global_step)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/ml/TAML/original_Tensorflow/misc_tf.py\u001b[0m in \u001b[0;36mget_train_op\u001b[1;34m(optim, loss, global_step, clip, var_list)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_train_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mupdate_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUPDATE_OPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   \u001b[0mgrad_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mclip\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     grad_and_vars = [((None if grad is None \\\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[0;32m    628\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[1;32m--> 630\u001b[1;33m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[0;32m    812\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 814\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    815\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    406\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    812\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 814\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    815\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_MaxPoolGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m       \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m       data_format=op.get_attr(\"data_format\"))\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_grad\u001b[1;34m(orig_input, orig_output, grad, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5079\u001b[0m         \u001b[1;34m\"MaxPoolGrad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morig_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morig_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5080\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5081\u001b[1;33m         data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5082\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5083\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1807\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1816\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1818\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reconstruct_sequence_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddOp\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m   2479\u001b[0m             \u001b[0mop_input_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2481\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_AddOpInternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_AddOpInternal\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m   2500\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2501\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m         \u001b[0mreal_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreal_x\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_x\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddValue\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m   2432\u001b[0m               \u001b[0mforward_ctxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2433\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mforward_ctxt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrad_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_context\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2434\u001b[1;33m             \u001b[0mreal_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetRealValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_external_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2436\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mGetRealValue\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[1;31m# Add the stack pop op in the grad context.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         real_value = cur_grad_state.AddBackpropAccumulatedValue(\n\u001b[1;32m-> 1153\u001b[1;33m             history_value, cur_value)\n\u001b[0m\u001b[0;32m   1154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcur_grad_state\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m           \u001b[0mreal_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddBackpropAccumulatedValue\u001b[1;34m(self, history_value, value, dead_branch)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[0mhistory_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_SwitchRefOrTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbranch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m       pop = gen_data_flow_ops.stack_pop_v2(history_value,\n\u001b[1;32m-> 1094\u001b[1;33m                                            value.dtype.base_dtype)\n\u001b[0m\u001b[0;32m   1095\u001b[0m       \u001b[0mpop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\u001b[0m in \u001b[0;36mstack_pop_v2\u001b[1;34m(handle, elem_type, name)\u001b[0m\n\u001b[0;32m   4874\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"elem_type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4875\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 4876\u001b[1;33m         \"StackPopV2\", handle=handle, elem_type=elem_type, name=name)\n\u001b[0m\u001b[0;32m   4877\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4878\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1796\u001b[0m     output_types = [\n\u001b[0;32m   1797\u001b[0m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOutputType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m         for i in range(num_outputs)]\n\u001b[0m\u001b[0;32m   1799\u001b[0m     self._outputs = [\n\u001b[0;32m   1800\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jason/anaconda3/envs/learningtobalance/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1796\u001b[0m     output_types = [\n\u001b[0;32m   1797\u001b[0m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOutputType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m         for i in range(num_outputs)]\n\u001b[0m\u001b[0;32m   1799\u001b[0m     self._outputs = [\n\u001b[0;32m   1800\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import model_tf\n",
    "imp.reload(model_tf)\n",
    "import data_tf\n",
    "imp.reload(data_tf)\n",
    "from accumulator_tf import Accumulator\n",
    "from misc_tf import get_train_op, print_balancing_variables, str2list\n",
    "\n",
    "# clear varaibles\n",
    "tf.reset_default_graph()\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_id)\n",
    "\n",
    "if not os.path.isdir(args.savedir):\n",
    "  os.makedirs(args.savedir)\n",
    "\n",
    "# for generating episode\n",
    "id_data =   OrderedDict([(data, data_tf.Data(data)) for data in args.id_dataset])\n",
    "ood_data =  OrderedDict([(data, data_tf.Data(data)) for data in args.ood_dataset])\n",
    "\n",
    "# model object\n",
    "model = model_tf.LearningToBalance(args)\n",
    "placeholders = model.get_placeholders()\n",
    "\n",
    "# with sampling (for meta-training)\n",
    "net = model.forward_outer_multiple(sample=True, reuse=False)\n",
    "net_cent = net['cent']\n",
    "net_kl = net['kl']\n",
    "net_acc = net['acc']\n",
    "net_acc_mean = tf.reduce_mean(net['acc'])\n",
    "\n",
    "# without sampling (for meta-validation)\n",
    "tnet = model.forward_outer_multiple(sample=False, reuse=True)\n",
    "tnet_cent = tnet['cent']\n",
    "tnet_kl = tnet['kl']\n",
    "tnet_acc = tnet['acc']\n",
    "tnet_acc_mean = tf.reduce_mean(tnet['acc'])\n",
    "tnet_weights = tnet['weights']\n",
    "\n",
    "def meta_train():\n",
    "  global_step = tf.train.get_or_create_global_step()\n",
    "  optim = tf.train.AdamOptimizer(args.meta_lr)\n",
    "  outer_loss = net_cent + net_kl\n",
    "  meta_train_op = get_train_op(optim, outer_loss, clip=[-3., 3.],\n",
    "      global_step=global_step)\n",
    "\n",
    "  saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=10)\n",
    "  logfile = open(os.path.join(args.savedir, 'train.log'), 'w')\n",
    "\n",
    "  # flush out the arguments\n",
    "  argdict = vars(args)\n",
    "  print(argdict)\n",
    "  for k, v in argdict.items():\n",
    "    logfile.write(k + ': ' + str(v) + '\\n')\n",
    "  logfile.write('\\n')\n",
    "\n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allow_growth = True\n",
    "  sess = tf.Session(config=config)\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  meta_train_logger = Accumulator('cent', 'kl', 'id_acc')\n",
    "  meta_train_to_run = [meta_train_op, net_cent, net_kl, net_acc_mean]\n",
    "\n",
    "  # multi-dataset meta-validation loggers\n",
    "  if len(args.id_dataset) > 1:\n",
    "    meta_val_logger = OrderedDict([(data_name, Accumulator('cent', 'kl', 'id_acc'))\n",
    "      for data_name in args.id_dataset + ['val']])\n",
    "  # single dataset meta-validation logger\n",
    "  else:\n",
    "    meta_val_logger = { 'val': Accumulator('cent', 'kl', 'id_acc', 'ood_acc') }\n",
    "  id_run = [tnet_cent, tnet_kl, tnet_acc_mean]\n",
    "  ood_run = tnet_acc_mean\n",
    "\n",
    "  for i in range(1, args.n_train_iters+1):\n",
    "    # feed_dict\n",
    "    data_name = args.id_dataset[i%len(args.id_dataset)]\n",
    "    episode = id_data[data_name].generate_episode(\n",
    "        args, split='mtr', n_episodes=args.metabatch)\n",
    "    fd_mtr = dict(zip(placeholders, episode))\n",
    "    meta_train_logger.accum(\n",
    "        sess.run(meta_train_to_run, feed_dict=fd_mtr))\n",
    "\n",
    "    if i % args.save_freq == 0:\n",
    "      saver.save(sess, os.path.join(args.savedir, 'model-{}'.format(i)))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "      line = 'Iter %d start, learning rate %f' % (i, args.meta_lr)\n",
    "      print('\\n' + line)\n",
    "      logfile.write('\\n' + line + '\\n')\n",
    "      meta_train_logger.print_(header='train', logfile=logfile)\n",
    "      meta_train_logger.clear()\n",
    "\n",
    "    # meta-validation\n",
    "    if i % 10000 == 0:\n",
    "      for j in range(3000 // args.metabatch):\n",
    "        # valdate on in-distribution (ID) dataset(s)\n",
    "        for data_name in args.id_dataset:\n",
    "          id_episode = id_data[data_name].generate_episode(\n",
    "              args, split='mval', n_episodes=args.metabatch)\n",
    "          id_cent, id_kl, id_acc = sess.run(id_run,\n",
    "              feed_dict=dict(zip(placeholders, id_episode)))\n",
    "\n",
    "          if len(args.id_dataset) > 1:\n",
    "            meta_val_logger[data_name].accum([id_cent, id_kl, id_acc])\n",
    "            meta_val_logger['val'].accum([id_cent, id_kl, id_acc])\n",
    "\n",
    "        # valiate on out-of-distribution (OOD) dataset\n",
    "        if args.ood_dataset[0] in ['svhn', 'cub']:\n",
    "          ood_episode = ood_data[args.ood_dataset[0]].generate_episode(\n",
    "              args, split='mval', n_episodes=args.metabatch)\n",
    "          ood_acc = sess.run(ood_run,\n",
    "              feed_dict=dict(zip(placeholders, ood_episode)))\n",
    "          meta_val_logger['val'].accum([id_cent, id_kl, id_acc, ood_acc])\n",
    "\n",
    "      for data_name, logger in meta_val_logger.items():\n",
    "          logger.print_(header='%s  '%data_name, logfile=logfile)\n",
    "          logger.clear()\n",
    "\n",
    "    # print balancing variables (omega, gamma) with 10 random tasks\n",
    "    if args.gamma_on or args.omega_on:\n",
    "      ntask = 10\n",
    "      if i % 1000 == 0:\n",
    "        testlist = [('ID ', id_data[args.id_dataset[0]])]\n",
    "        if len(args.id_dataset) == 1:\n",
    "          testlist.append(('OOD', ood_data[args.ood_dataset[0]]))\n",
    "        for flag, data in testlist:\n",
    "          # episode\n",
    "          episode = data.generate_episode(\n",
    "              args, split='mval', n_episodes=ntask)\n",
    "          omega, gamma = sess.run(\n",
    "              model.get_balancing_variables(ntask=ntask),\n",
    "              feed_dict=dict(zip(placeholders, episode)))\n",
    "\n",
    "          print_balancing_variables(\n",
    "              args, flag, episode, ntask, omega, gamma, logfile)\n",
    "\n",
    "  logfile.close()\n",
    "\n",
    "def meta_test():\n",
    "  # choose the best model\n",
    "  f = open(os.path.join(args.savedir, 'train.log'), 'r')\n",
    "  lines = [l.split(' ') for l in f.readlines()]\n",
    "  acc_id, acc_ood, idx_list = [], [], []\n",
    "  for i, l in enumerate(lines):\n",
    "    if l[0] == 'val':\n",
    "      if len(args.id_dataset) > 1:\n",
    "        idx_list.append(int(lines[i-5][1]))\n",
    "        acc_id.append(float(l[-1]))\n",
    "      else:\n",
    "        idx_list.append(int(lines[i-2][1]))\n",
    "        acc_id.append(float(l[-3][:-1]))\n",
    "        acc_ood.append(float(l[-1]))\n",
    "  acc = np.array(acc_id) if len(args.id_dataset) > 1 \\\n",
    "          else np.array(acc_id) + np.array(acc_ood)\n",
    "  best_idx = idx_list[np.argmax(acc)]\n",
    "\n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allow_growth = True\n",
    "  sess = tf.Session(config=config)\n",
    "  saver = tf.train.Saver(tnet_weights, max_to_keep=10)\n",
    "  saver.restore(sess, os.path.join(args.savedir, 'model-%d' % best_idx))\n",
    "\n",
    "  logfile = open(os.path.join(args.savedir,\n",
    "    'test_step%d_mc%d.log' % (args.n_steps, args.n_mc_samples)), 'w')\n",
    "  start = time.time()\n",
    "\n",
    "  line = '\\nMeta-test model-%d\\n' % best_idx\n",
    "  print(line)\n",
    "  logfile.write(line + '\\n')\n",
    "\n",
    "  if args.n_mc_samples > 0:\n",
    "    to_run = model.forward_outer_multiple_repeat(n_sample=args.n_mc_samples)\n",
    "  else:\n",
    "    to_run = tnet_acc\n",
    "\n",
    "  for flag, datalist in [('id ', id_data), ('ood', ood_data)]:\n",
    "    for data_name, data in datalist.items():\n",
    "      acc = []\n",
    "      for j in range(args.n_test_episodes // args.metabatch):\n",
    "        placeholders = model.get_placeholders()\n",
    "        episode = data.generate_episode(\n",
    "            args, split='mte', n_episodes=args.metabatch)\n",
    "        acc.append(sess.run(\n",
    "          to_run, feed_dict=dict(zip(placeholders, episode))))\n",
    "        if (j+1)*args.metabatch % 100 == 0:\n",
    "          print('(%.3f secs) test episode %d done' \\\n",
    "              % (time.time()-start, (j+1)*args.metabatch ))\n",
    "\n",
    "      acc = 100.*np.concatenate(acc, axis=0)\n",
    "      acc_mean = np.mean(acc)\n",
    "      acc_95conf = 1.96*np.std(acc)/float(np.sqrt(args.n_test_episodes))\n",
    "      result = '%s/%s acc: %.2f +- %.2f\\n'%(flag, data_name, acc_mean, acc_95conf)\n",
    "      print(result)\n",
    "      logfile.write(result)\n",
    "\n",
    "  logfile.close()\n",
    "\n",
    "if args.mode == 'meta_train':\n",
    "    meta_train()\n",
    "if args.mode == 'meta_test':\n",
    "    meta_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learningtobalance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
