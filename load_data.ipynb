{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3b94faa",
   "metadata": {},
   "source": [
    "# **prepares data, store in .pickle file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5ca00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "# path dictionary\n",
    "path_data_folder = \"5.9.23/\"\n",
    "path_dictionary = {\n",
    "    '20.7': path_data_folder + \"twentypointseven\",\n",
    "    '21.0': path_data_folder + \"twentyonepointzero_1\",\n",
    "    '21.2': path_data_folder + \"twentyonepointtwo_1\",\n",
    "    '21.5': path_data_folder + \"twentyonepointfive_1\",\n",
    "    '21.7': path_data_folder + \"TwentyonepointseevendegreeC_1\",\n",
    "    '21.8': path_data_folder + \"twentypointeight_1\"\n",
    "}\n",
    "# separator in this file is tab\n",
    "# label for entire file is the temperature\n",
    "# frames = pd.read_csv(\"5.9.23/twentypointseven\", sep=\"\\t\", header=None)\n",
    "# # <- pandas index is [column][row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84655847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data are (1000 * 1) column vectors.\n",
    "# in the file, there are 1000 lines, each with n numbers, \n",
    "# where n = number of data vectors\n",
    "def load_data(filename_dictionary):\n",
    "    X_data = [] # data\n",
    "    y_data = [] # label\n",
    "    for filename, filepath in filename_dictionary.items():\n",
    "        print(f\"reading file:        {filepath}\")\n",
    "        X_in_this_file = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "        value = float(filename)\n",
    "        print(f\"\\ttemperature value: {value}\")\n",
    "        number_of_examples = X_in_this_file.shape[0]\n",
    "        y_in_this_file = np.zeros(shape=(number_of_examples)) + value\n",
    "        y_in_this_file = pd.DataFrame(y_in_this_file)\n",
    "        # default column setting is NO array, \n",
    "        # need to make it array to use list of indices!\n",
    "        y_in_this_file.columns = np.asarray(range(y_in_this_file.shape[1]))\n",
    "        X_data.append(X_in_this_file)\n",
    "        y_data.append(y_in_this_file)\n",
    "    X_data = pd.concat(X_data, axis=0, ignore_index=True)\n",
    "    y_data = pd.concat(y_data, axis=0, ignore_index=True)\n",
    "    return np.asarray(X_data), np.asarray(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0373a910-6be0-4875-aae2-f58929440230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file:        5.9.23/twentypointseven\n",
      "\ttemperature value: 20.7\n",
      "reading file:        5.9.23/twentyonepointzero_1\n",
      "\ttemperature value: 21.0\n",
      "reading file:        5.9.23/twentyonepointtwo_1\n",
      "\ttemperature value: 21.2\n",
      "reading file:        5.9.23/twentyonepointfive_1\n",
      "\ttemperature value: 21.5\n",
      "reading file:        5.9.23/TwentyonepointseevendegreeC_1\n",
      "\ttemperature value: 21.7\n",
      "reading file:        5.9.23/twentypointeight_1\n",
      "\ttemperature value: 21.8\n",
      "\n",
      "total number of examples:     6000\n",
      "length of each example:       10000\n",
      "shape of X data (spectrum): (6000, 10000), type: float64\n",
      "shape of y data (temperature): (6000, 1), type: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "import pandas as pd\n",
    "# change: response (X) -> spectrum, spectra (y) -> temperature\n",
    "\n",
    "spectrum_raw, temperature_raw = load_data(filename_dictionary=path_dictionary)\n",
    "print()\n",
    "print(f\"total number of examples:     {spectrum_raw.shape[0]}\")\n",
    "print(f\"length of each example:       {spectrum_raw.shape[1]}\")\n",
    "print(f\"shape of X data (spectrum): {spectrum_raw.shape}, type: {spectrum_raw[0][0].dtype}\")\n",
    "print(f\"shape of y data (temperature): {temperature_raw.shape}, type: {temperature_raw[0].dtype}\")\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "723e2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test with 6418th column\n",
      "normalized mean will not be exactly 0, but very close to it!\n",
      "SPECTRUM\n",
      "6418th column: before normalization: \n",
      "[0.856 0.848 0.856 ... 0.608 0.608 0.6  ]\n",
      "mean = 0.916909333333365\n",
      "6418th column: after normalization: \n",
      "[-0.63137683 -0.7143036  -0.63137683 ... -3.20210687 -3.20210687\n",
      " -3.28503365]\n",
      "mean = 1.5329219375341079e-15\n",
      "TEMPERATURE\n",
      "0th column: \n",
      "[20.7 20.7 20.7 ... 21.8 21.8 21.8]\n",
      "mean = 21.316666666666247\n"
     ]
    }
   ],
   "source": [
    "\"\"\"normalization: longer sklearn implementation\"\"\"\n",
    "# more code, but can change type of scaler easily\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "# data is an np array\n",
    "#   a row = a vector\n",
    "#   a column = a feature\n",
    "def normalize(data):\n",
    "    # normalize direction: column (feature)-wise\n",
    "    scaler = StandardScaler() # change scaler here\n",
    "    eg_ct = data.shape[0]\n",
    "    feature_ct = data.shape[1]\n",
    "    normalized_data = np.zeros(shape=(eg_ct, feature_ct))\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "    # for f in range(feature_ct):\n",
    "    #     array = data[:,f]\n",
    "    #     if array.ndim < 2: \n",
    "    #         array = np.reshape(array, newshape=(-1, 1))\n",
    "    #     normalized_data[:,f] = scaler.fit_transform(array).reshape(-1)\n",
    "    return normalized_data, scaler\n",
    "\n",
    "index = random.randint(0, spectrum_raw.shape[1] - 1)\n",
    "print(f\"test with {index}th column\")\n",
    "print(\"normalized mean will not be exactly 0, but very close to it!\")\n",
    "spectrum, spectrum_scaler = normalize(spectrum_raw)\n",
    "print(\"SPECTRUM\")\n",
    "print(f\"{index}th column: before normalization: \\n{spectrum_raw[:,index]}\")\n",
    "print(f\"mean = {sum(spectrum_raw[:,index])/spectrum_raw.shape[0]}\")\n",
    "print(f\"{index}th column: after normalization: \\n{spectrum[:,index]}\")\n",
    "print(f\"mean = {sum(spectrum[:,index])/spectrum_raw.shape[0]}\")\n",
    "\n",
    "# temperature, temperature_scaler = normalize(temperature_raw)\n",
    "temperature = temperature_raw\n",
    "print(\"TEMPERATURE\")\n",
    "# print(f\"0th column: before normalization: {temperature_raw[:,0]}\")\n",
    "# print(f\"mean = {sum(temperature_raw[:,0])/spectrum_raw.shape[0]}\")\n",
    "# print(f\"0th column: after normalization: {temperature[:,0]}\")\n",
    "# print(f\"mean = {sum(temperature[:,0])/spectrum_raw.shape[0]}\")\n",
    "print(f\"0th column: \\n{temperature_raw[:,0]}\")\n",
    "print(f\"mean = {sum(temperature_raw[:,0])/spectrum_raw.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29e9b94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved data in data_normalized.pickle file\n",
      "saved scaler in data_scaler.pickle file\n"
     ]
    }
   ],
   "source": [
    "# saving preprocessed\n",
    "normalized_data_file_name = 'data_normalized'\n",
    "with open(normalized_data_file_name + '.pickle', 'wb') as handle:\n",
    "    pickle.dump([spectrum, temperature], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"saved data in {normalized_data_file_name}.pickle file\")\n",
    "normalized_data_scaler_file_name = 'data_scaler'\n",
    "with open(normalized_data_scaler_file_name + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(spectrum_scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"saved scaler in {normalized_data_scaler_file_name}.pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18063aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify: reading data\n",
      "read data from data_normalized.pickle\n",
      "read spectrum correctly: True\n",
      "read temperature correctly: True\n",
      "\n",
      "verify: reading data scaler\n",
      "read scaler from data_normalized.pickle\n",
      "recover spectrum:\n",
      "6418th column: after normalization: [-0.63137683 -0.7143036  -0.63137683 ... -3.20210687 -3.20210687\n",
      " -3.28503365]\n",
      "6418th column: recovered: [0.856 0.848 0.856 ... 0.608 0.608 0.6  ]\n",
      "6418th column: original: [0.856 0.848 0.856 ... 0.608 0.608 0.6  ]\n",
      "recover temperature:\n",
      "0th column: original: [20.7 20.7 20.7 ... 21.8 21.8 21.8]\n"
     ]
    }
   ],
   "source": [
    "# try reading data\n",
    "print(\"verify: reading data\")\n",
    "with open(normalized_data_file_name + '.pickle', 'rb') as handle:\n",
    "    spectrum_test_read, temperature_test_read = pickle.load(handle)\n",
    "    print(f\"read data from {normalized_data_file_name}.pickle\") \n",
    "print(f\"read spectrum correctly: {np.array_equal(spectrum, spectrum_test_read)}\")\n",
    "print(f\"read temperature correctly: {np.array_equal(temperature, temperature_test_read)}\")\n",
    "print()\n",
    "print(\"verify: reading data scaler\")\n",
    "with open(normalized_data_scaler_file_name + '.pickle', 'rb') as handle:\n",
    "    spectrum_test_read_scaler = pickle.load(handle)\n",
    "    print(f\"read scaler from {normalized_data_file_name}.pickle\") \n",
    "print(\"recover spectrum:\")\n",
    "print(f\"{index}th column: after normalization: {spectrum_test_read[:,index]}\")\n",
    "recover_spectrum_eg = spectrum_test_read_scaler.inverse_transform(spectrum_test_read)[:,index]\n",
    "print(f\"{index}th column: recovered: {recover_spectrum_eg.reshape(-1)}\")\n",
    "print(f\"{index}th column: original: {spectrum_raw[:,index]}\")\n",
    "print(\"recover temperature:\")\n",
    "# print(f\"0th column: after normalization: {temperature_test_read[:,0]}\")\n",
    "# recover_temperature_eg = temperature_test_read_scaler.inverse_transform(temperature_test_read[:,0].reshape(-1, 1))\n",
    "# print(f\"0th column: recovered: {recover_temperature_eg.reshape(-1)}\")\n",
    "print(f\"0th column: original: {temperature_raw[:,0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8584e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorter pandas implementation, also work (very small difference in value)\n",
    "# less code, but more changes needed to change normalization method\n",
    "# spectrum = spectrum_raw.sub(spectrum_raw.mean(axis=1), axis=0).div(spectrum_raw.std(axis=1), axis=0)\n",
    "# print(f\"0th row: before normalization: {spectrum_raw.iloc[0]}\")\n",
    "# print(f\"mean = {sum(spectrum_raw.iloc[0])/spectrum_raw.shape[1]}\")\n",
    "# print(f\"0th row: after normalization: {spectrum.iloc[0]}\")\n",
    "# print(f\"mean = {sum(spectrum.iloc[0])/spectrum_raw.shape[1]}\")\n",
    "# temperature = temperature_raw.sub(temperature_raw.mean(axis=1), axis=0).div(temperature_raw.std(axis=1), axis=0)\n",
    "# print(f\"0th row: before normalization: {temperature_raw.iloc[0]}\")\n",
    "# print(f\"mean = {sum(temperature_raw.iloc[0])/spectrum_raw.shape[1]}\")\n",
    "# print(f\"0th row: after normalization: {temperature.iloc[0]}\")\n",
    "# print(f\"mean = {sum(temperature.iloc[0])/spectrum_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6558b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got indices by KFold method, fold = 5, resample = 2\n",
      "saved indices in cross_validation_resample=2_fold=5.pickle file\n",
      "\n",
      "sets of training indices: 10\n",
      "number of training indices per set: 4800\n",
      "sets of testing indices: 10\n",
      "number of testing indices per set: 1200\n"
     ]
    }
   ],
   "source": [
    "# get & save indices\n",
    "import os.path\n",
    "file_name = 'cross_validation_resample=2_fold=5'\n",
    "    # 2x5 resampling\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "number_resamples = 2\n",
    "n_splits =5\n",
    "eg_ct = temperature.shape[0]\n",
    "\n",
    "for i in range(number_resamples):\n",
    "    kf = KFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(range(eg_ct))):\n",
    "        train_indices.append(train_index)\n",
    "        test_indices.append(test_index)\n",
    "print(f\"got indices by KFold method, fold = {n_splits}, resample = {number_resamples}\")\n",
    "with open(file_name+'.pickle', 'wb') as handle:\n",
    "    pickle.dump([train_indices,test_indices], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(f\"saved indices in {file_name}.pickle file\")\n",
    "print()\n",
    "print(f\"sets of training indices: {len(train_indices)}\")\n",
    "print(f\"number of training indices per set: {len(train_indices[0])}\")\n",
    "print(f\"sets of testing indices: {len(test_indices)}\")\n",
    "print(f\"number of testing indices per set: {len(test_indices[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbe70366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got indices from cross_validation_resample=2_fold=5.pickle\n",
      "train_indices row 1: [   0    1    2 ... 5997 5998 5999]\n",
      "\tnumber of folds: 10\n",
      "\tnumber of indices per fold: 4800\n",
      "test_index row 1: [   9   18   22 ... 5985 5992 5996]\n",
      "\tnumber of folds: 10\n",
      "\tnumber of indices per fold: 1200\n"
     ]
    }
   ],
   "source": [
    "# test read indices\n",
    "index = 1\n",
    "with open(file_name+'.pickle', 'rb') as handle:\n",
    "    train_indices_test_read , test_indices_test_read = pickle.load(handle)\n",
    "    print(f\"got indices from {file_name}.pickle\")  \n",
    "print(f\"train_indices row {index}: {train_indices_test_read[index]}\")\n",
    "print(f\"\\tnumber of folds: {len(train_indices_test_read)}\")\n",
    "print(f\"\\tnumber of indices per fold: {len(train_indices_test_read[index])}\")\n",
    "print(f\"test_index row {index}: {test_indices_test_read[index]}\")\n",
    "print(f\"\\tnumber of folds: {len(test_indices_test_read)}\")\n",
    "print(f\"\\tnumber of indices per fold: {len(test_indices_test_read[index])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
